{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from dataset import ModelNet40Dataset\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filehandler = open('ModelNet40ProcessedDataset', 'rb') \n",
    "ModelNet40Data = pickle.load(filehandler)\n",
    "\n",
    "# print(len(ModelNet40Data.train['pcds']))\n",
    "def sample_data(data,batch_size):\n",
    "    total_N = len(data['pcds'])\n",
    "    indices = np.random.choice(total_N,batch_size,replace = False)\n",
    "    N_pts,d =  data['pcds'][0].shape\n",
    "    pcds = np.zeros((batch_size,N_pts,d))\n",
    "    labels = np.zeros(batch_size,dtype=int)\n",
    "    for i in range(batch_size):\n",
    "        pcd = data['pcds'][indices[i]]\n",
    "        #rotate pointcloud\n",
    "        a = np.random.rand()*math.pi\n",
    "        R = np.array([[math.cos(a),-math.sin(a),0.],\\\n",
    "              [math.sin(a),math.cos(a),0.],\\\n",
    "              [0.,0.,1.]])\n",
    "        pcd = pcd.dot(R)\n",
    "        #jitter\n",
    "        pcd += np.random.normal(0,0.02,size=pcd.shape)      \n",
    "        pcds[i,:,:] = pcd\n",
    "        labels[i] = int(data['labels'][indices[i]])\n",
    "    return pcds,labels\n",
    "    \n",
    "def get_data(data):\n",
    "    total_N = 600 #len(data['pcds'])\n",
    "    indices = np.arange(total_N)\n",
    "    N_pts,d =  data['pcds'][0].shape\n",
    "    pcds = np.zeros((total_N,N_pts,d))\n",
    "    labels = np.zeros(total_N,dtype=int)\n",
    "    for i in range(total_N):\n",
    "        #rotate and jitter pointcloud\n",
    "        pcds[i,:,:] = data['pcds'][indices[i]]\n",
    "        labels[i] = int(data['labels'][indices[i]])\n",
    "    return pcds,labels\n",
    "\n",
    "def compute_accuracy(preds,target):\n",
    "    tmp = preds.max(1).indices == target\n",
    "    return torch.sum(tmp).detach().cpu().numpy()/target.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters\n",
    "N_CLASSES = 40\n",
    "EPOCHS = 1000#2000\n",
    "BATCH_SIZE = 32\n",
    "INIT_LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "LR_STEP = 20\n",
    "SCHEDULER_GAMMA = 0.5\n",
    "TEST_EVERY = 1\n",
    "REG_WEIGHT = 0.001\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = PointNetClassification(N_CLASSES).to(device)\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=INIT_LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP, gamma=SCHEDULER_GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ;train and test accuracies: 0.0 0.03125\n",
      "Epoch: 1 ;train and test accuracies: 0.0 0.03125\n",
      "Epoch: 2 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 3 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 4 ;train and test accuracies: 0.03125 0.0\n",
      "Epoch: 5 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 6 ;train and test accuracies: 0.03125 0.03125\n",
      "Epoch: 7 ;train and test accuracies: 0.0 0.0\n",
      "Epoch: 8 ;train and test accuracies: 0.03125 0.03125\n",
      "Epoch: 9 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 10 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 11 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 12 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 13 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 14 ;train and test accuracies: 0.0625 0.0\n",
      "Epoch: 15 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 16 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 17 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 18 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 19 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 20 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 21 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 22 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 23 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 24 ;train and test accuracies: 0.09375 0.0\n",
      "Epoch: 25 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 26 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 27 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 28 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 29 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 30 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 31 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 32 ;train and test accuracies: 0.0625 0.0\n",
      "Epoch: 33 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 34 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 35 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 36 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 37 ;train and test accuracies: 0.0625 0.0\n",
      "Epoch: 38 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 39 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 40 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 41 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 42 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 43 ;train and test accuracies: 0.09375 0.0\n",
      "Epoch: 44 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 45 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 46 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 47 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 48 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 49 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 50 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 51 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 52 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 53 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 54 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 55 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 56 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 57 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 58 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 59 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 60 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 61 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 62 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 63 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 64 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 65 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 66 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 67 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 68 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 69 ;train and test accuracies: 0.0 0.15625\n",
      "Epoch: 70 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 71 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 72 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 73 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 74 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 75 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 76 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 77 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 78 ;train and test accuracies: 0.3125 0.15625\n",
      "Epoch: 79 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 80 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 81 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 82 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 83 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 84 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 85 ;train and test accuracies: 0.28125 0.09375\n",
      "Epoch: 86 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 87 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 88 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 89 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 90 ;train and test accuracies: 0.09375 0.1875\n",
      "Epoch: 91 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 92 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 93 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 94 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 95 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 96 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 97 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 98 ;train and test accuracies: 0.15625 0.1875\n",
      "Epoch: 99 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 100 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 101 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 102 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 103 ;train and test accuracies: 0.15625 0.21875\n",
      "Epoch: 104 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 105 ;train and test accuracies: 0.03125 0.125\n",
      "Epoch: 106 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 107 ;train and test accuracies: 0.1875 0.21875\n",
      "Epoch: 108 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 109 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 110 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 111 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 112 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 113 ;train and test accuracies: 0.1875 0.25\n",
      "Epoch: 114 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 115 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 116 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 117 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 118 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 119 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 120 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 121 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 122 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 123 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 124 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 125 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 126 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 127 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 128 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 129 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 130 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 131 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 132 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 133 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 134 ;train and test accuracies: 0.28125 0.15625\n",
      "Epoch: 135 ;train and test accuracies: 0.3125 0.125\n",
      "Epoch: 136 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 137 ;train and test accuracies: 0.3125 0.15625\n",
      "Epoch: 138 ;train and test accuracies: 0.03125 0.15625\n",
      "Epoch: 139 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 140 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 141 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 142 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 143 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 144 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 145 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 146 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 147 ;train and test accuracies: 0.3125 0.0625\n",
      "Epoch: 148 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 149 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 150 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 151 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 152 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 153 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 154 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 155 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 156 ;train and test accuracies: 0.21875 0.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 158 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 159 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 160 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 161 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 162 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 163 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 164 ;train and test accuracies: 0.09375 0.0\n",
      "Epoch: 165 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 166 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 167 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 168 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 169 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 170 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 171 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 172 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 173 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 174 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 175 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 176 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 177 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 178 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 179 ;train and test accuracies: 0.0625 0.1875\n",
      "Epoch: 180 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 181 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 182 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 183 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 184 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 185 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 186 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 187 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 188 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 189 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 190 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 191 ;train and test accuracies: 0.03125 0.1875\n",
      "Epoch: 192 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 193 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 194 ;train and test accuracies: 0.0625 0.15625\n",
      "Epoch: 195 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 196 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 197 ;train and test accuracies: 0.03125 0.125\n",
      "Epoch: 198 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 199 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 200 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 201 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 202 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 203 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 204 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 205 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 206 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 207 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 208 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 209 ;train and test accuracies: 0.09375 0.1875\n",
      "Epoch: 210 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 211 ;train and test accuracies: 0.25 0.1875\n",
      "Epoch: 212 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 213 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 214 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 215 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 216 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 217 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 218 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 219 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 220 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 221 ;train and test accuracies: 0.0625 0.21875\n",
      "Epoch: 222 ;train and test accuracies: 0.0625 0.15625\n",
      "Epoch: 223 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 224 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 225 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 226 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 227 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 228 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 229 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 230 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 231 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 232 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 233 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 234 ;train and test accuracies: 0.28125 0.21875\n",
      "Epoch: 235 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 236 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 237 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 238 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 239 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 240 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 241 ;train and test accuracies: 0.0 0.0625\n",
      "Epoch: 242 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 243 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 244 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 245 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 246 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 247 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 248 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 249 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 250 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 251 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 252 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 253 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 254 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 255 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 256 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 257 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 258 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 259 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 260 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 261 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 262 ;train and test accuracies: 0.25 0.1875\n",
      "Epoch: 263 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 264 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 265 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 266 ;train and test accuracies: 0.25 0.15625\n",
      "Epoch: 267 ;train and test accuracies: 0.375 0.15625\n",
      "Epoch: 268 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 269 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 270 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 271 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 272 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 273 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 274 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 275 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 276 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 277 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 278 ;train and test accuracies: 0.09375 0.21875\n",
      "Epoch: 279 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 280 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 281 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 282 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 283 ;train and test accuracies: 0.09375 0.25\n",
      "Epoch: 284 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 285 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 286 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 287 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 288 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 289 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 290 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 291 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 292 ;train and test accuracies: 0.0625 0.15625\n",
      "Epoch: 293 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 294 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 295 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 296 ;train and test accuracies: 0.03125 0.0\n",
      "Epoch: 297 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 298 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 299 ;train and test accuracies: 0.15625 0.21875\n",
      "Epoch: 300 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 301 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 302 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 303 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 304 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 305 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 306 ;train and test accuracies: 0.125 0.25\n",
      "Epoch: 307 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 308 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 309 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 310 ;train and test accuracies: 0.1875 0.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 311 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 312 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 313 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 314 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 315 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 316 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 317 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 318 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 319 ;train and test accuracies: 0.09375 0.21875\n",
      "Epoch: 320 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 321 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 322 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 323 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 324 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 325 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 326 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 327 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 328 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 329 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 330 ;train and test accuracies: 0.34375 0.0625\n",
      "Epoch: 331 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 332 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 333 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 334 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 335 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 336 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 337 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 338 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 339 ;train and test accuracies: 0.3125 0.09375\n",
      "Epoch: 340 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 341 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 342 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 343 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 344 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 345 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 346 ;train and test accuracies: 0.125 0.21875\n",
      "Epoch: 347 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 348 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 349 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 350 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 351 ;train and test accuracies: 0.3125 0.0625\n",
      "Epoch: 352 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 353 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 354 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 355 ;train and test accuracies: 0.375 0.09375\n",
      "Epoch: 356 ;train and test accuracies: 0.25 0.1875\n",
      "Epoch: 357 ;train and test accuracies: 0.25 0.1875\n",
      "Epoch: 358 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 359 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 360 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 361 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 362 ;train and test accuracies: 0.1875 0.21875\n",
      "Epoch: 363 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 364 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 365 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 366 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 367 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 368 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 369 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 370 ;train and test accuracies: 0.25 0.15625\n",
      "Epoch: 371 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 372 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 373 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 374 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 375 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 376 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 377 ;train and test accuracies: 0.40625 0.03125\n",
      "Epoch: 378 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 379 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 380 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 381 ;train and test accuracies: 0.03125 0.1875\n",
      "Epoch: 382 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 383 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 384 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 385 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 386 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 387 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 388 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 389 ;train and test accuracies: 0.03125 0.03125\n",
      "Epoch: 390 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 391 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 392 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 393 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 394 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 395 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 396 ;train and test accuracies: 0.21875 0.1875\n",
      "Epoch: 397 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 398 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 399 ;train and test accuracies: 0.28125 0.09375\n",
      "Epoch: 400 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 401 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 402 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 403 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 404 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 405 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 406 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 407 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 408 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 409 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 410 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 411 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 412 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 413 ;train and test accuracies: 0.0 0.03125\n",
      "Epoch: 414 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 415 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 416 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 417 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 418 ;train and test accuracies: 0.28125 0.15625\n",
      "Epoch: 419 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 420 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 421 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 422 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 423 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 424 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 425 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 426 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 427 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 428 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 429 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 430 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 431 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 432 ;train and test accuracies: 0.28125 0.09375\n",
      "Epoch: 433 ;train and test accuracies: 0.25 0.15625\n",
      "Epoch: 434 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 435 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 436 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 437 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 438 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 439 ;train and test accuracies: 0.28125 0.09375\n",
      "Epoch: 440 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 441 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 442 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 443 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 444 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 445 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 446 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 447 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 448 ;train and test accuracies: 0.0625 0.15625\n",
      "Epoch: 449 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 450 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 451 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 452 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 453 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 454 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 455 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 456 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 457 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 458 ;train and test accuracies: 0.25 0.1875\n",
      "Epoch: 459 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 460 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 461 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 462 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 463 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 464 ;train and test accuracies: 0.125 0.03125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 465 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 466 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 467 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 468 ;train and test accuracies: 0.03125 0.125\n",
      "Epoch: 469 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 470 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 471 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 472 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 473 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 474 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 475 ;train and test accuracies: 0.3125 0.03125\n",
      "Epoch: 476 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 477 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 478 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 479 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 480 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 481 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 482 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 483 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 484 ;train and test accuracies: 0.28125 0.09375\n",
      "Epoch: 485 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 486 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 487 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 488 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 489 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 490 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 491 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 492 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 493 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 494 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 495 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 496 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 497 ;train and test accuracies: 0.3125 0.03125\n",
      "Epoch: 498 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 499 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 500 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 501 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 502 ;train and test accuracies: 0.1875 0.25\n",
      "Epoch: 503 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 504 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 505 ;train and test accuracies: 0.28125 0.15625\n",
      "Epoch: 506 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 507 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 508 ;train and test accuracies: 0.15625 0.21875\n",
      "Epoch: 509 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 510 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 511 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 512 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 513 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 514 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 515 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 516 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 517 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 518 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 519 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 520 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 521 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 522 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 523 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 524 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 525 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 526 ;train and test accuracies: 0.03125 0.03125\n",
      "Epoch: 527 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 528 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 529 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 530 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 531 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 532 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 533 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 534 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 535 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 536 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 537 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 538 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 539 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 540 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 541 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 542 ;train and test accuracies: 0.3125 0.125\n",
      "Epoch: 543 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 544 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 545 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 546 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 547 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 548 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 549 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 550 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 551 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 552 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 553 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 554 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 555 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 556 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 557 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 558 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 559 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 560 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 561 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 562 ;train and test accuracies: 0.25 0.0\n",
      "Epoch: 563 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 564 ;train and test accuracies: 0.15625 0.1875\n",
      "Epoch: 565 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 566 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 567 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 568 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 569 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 570 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 571 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 572 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 573 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 574 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 575 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 576 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 577 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 578 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 579 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 580 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 581 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 582 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 583 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 584 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 585 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 586 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 587 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 588 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 589 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 590 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 591 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 592 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 593 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 594 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 595 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 596 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 597 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 598 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 599 ;train and test accuracies: 0.03125 0.125\n",
      "Epoch: 600 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 601 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 602 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 603 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 604 ;train and test accuracies: 0.0625 0.1875\n",
      "Epoch: 605 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 606 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 607 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 608 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 609 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 610 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 611 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 612 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 613 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 614 ;train and test accuracies: 0.3125 0.09375\n",
      "Epoch: 615 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 616 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 617 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 618 ;train and test accuracies: 0.09375 0.03125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 619 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 620 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 621 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 622 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 623 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 624 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 625 ;train and test accuracies: 0.25 0.15625\n",
      "Epoch: 626 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 627 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 628 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 629 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 630 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 631 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 632 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 633 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 634 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 635 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 636 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 637 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 638 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 639 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 640 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 641 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 642 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 643 ;train and test accuracies: 0.25 0.0\n",
      "Epoch: 644 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 645 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 646 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 647 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 648 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 649 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 650 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 651 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 652 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 653 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 654 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 655 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 656 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 657 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 658 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 659 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 660 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 661 ;train and test accuracies: 0.0625 0.0\n",
      "Epoch: 662 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 663 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 664 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 665 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 666 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 667 ;train and test accuracies: 0.28125 0.09375\n",
      "Epoch: 668 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 669 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 670 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 671 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 672 ;train and test accuracies: 0.0625 0.0\n",
      "Epoch: 673 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 674 ;train and test accuracies: 0.125 0.21875\n",
      "Epoch: 675 ;train and test accuracies: 0.15625 0.1875\n",
      "Epoch: 676 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 677 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 678 ;train and test accuracies: 0.09375 0.1875\n",
      "Epoch: 679 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 680 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 681 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 682 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 683 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 684 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 685 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 686 ;train and test accuracies: 0.3125 0.0625\n",
      "Epoch: 687 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 688 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 689 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 690 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 691 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 692 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 693 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 694 ;train and test accuracies: 0.15625 0.21875\n",
      "Epoch: 695 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 696 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 697 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 698 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 699 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 700 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 701 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 702 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 703 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 704 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 705 ;train and test accuracies: 0.21875 0.0625\n",
      "Epoch: 706 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 707 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 708 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 709 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 710 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 711 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 712 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 713 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 714 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 715 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 716 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 717 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 718 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 719 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 720 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 721 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 722 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 723 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 724 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 725 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 726 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 727 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 728 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 729 ;train and test accuracies: 0.25 0.1875\n",
      "Epoch: 730 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 731 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 732 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 733 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 734 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 735 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 736 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 737 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 738 ;train and test accuracies: 0.3125 0.03125\n",
      "Epoch: 739 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 740 ;train and test accuracies: 0.03125 0.15625\n",
      "Epoch: 741 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 742 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 743 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 744 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 745 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 746 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 747 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 748 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 749 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 750 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 751 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 752 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 753 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 754 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 755 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 756 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 757 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 758 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 759 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 760 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 761 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 762 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 763 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 764 ;train and test accuracies: 0.0 0.09375\n",
      "Epoch: 765 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 766 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 767 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 768 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 769 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 770 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 771 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 772 ;train and test accuracies: 0.25 0.09375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 773 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 774 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 775 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 776 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 777 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 778 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 779 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 780 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 781 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 782 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 783 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 784 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 785 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 786 ;train and test accuracies: 0.34375 0.03125\n",
      "Epoch: 787 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 788 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 789 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 790 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 791 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 792 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 793 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 794 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 795 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 796 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 797 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 798 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 799 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 800 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 801 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 802 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 803 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 804 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 805 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 806 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 807 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 808 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 809 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 810 ;train and test accuracies: 0.25 0.15625\n",
      "Epoch: 811 ;train and test accuracies: 0.1875 0.28125\n",
      "Epoch: 812 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 813 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 814 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 815 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 816 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 817 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 818 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 819 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 820 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 821 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 822 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 823 ;train and test accuracies: 0.34375 0.0625\n",
      "Epoch: 824 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 825 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 826 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 827 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 828 ;train and test accuracies: 0.09375 0.21875\n",
      "Epoch: 829 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 830 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 831 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 832 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 833 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 834 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 835 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 836 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 837 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 838 ;train and test accuracies: 0.03125 0.15625\n",
      "Epoch: 839 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 840 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 841 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 842 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 843 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 844 ;train and test accuracies: 0.03125 0.0625\n",
      "Epoch: 845 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 846 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 847 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 848 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 849 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 850 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 851 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 852 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 853 ;train and test accuracies: 0.15625 0.21875\n",
      "Epoch: 854 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 855 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 856 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 857 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 858 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 859 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 860 ;train and test accuracies: 0.3125 0.09375\n",
      "Epoch: 861 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 862 ;train and test accuracies: 0.15625 0.1875\n",
      "Epoch: 863 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 864 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 865 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 866 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 867 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 868 ;train and test accuracies: 0.09375 0.03125\n",
      "Epoch: 869 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 870 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 871 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 872 ;train and test accuracies: 0.3125 0.09375\n",
      "Epoch: 873 ;train and test accuracies: 0.1875 0.1875\n",
      "Epoch: 874 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 875 ;train and test accuracies: 0.125 0.21875\n",
      "Epoch: 876 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 877 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 878 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 879 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 880 ;train and test accuracies: 0.09375 0.21875\n",
      "Epoch: 881 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 882 ;train and test accuracies: 0.1875 0.15625\n",
      "Epoch: 883 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 884 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 885 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 886 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 887 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 888 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 889 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 890 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 891 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 892 ;train and test accuracies: 0.15625 0.21875\n",
      "Epoch: 893 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 894 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 895 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 896 ;train and test accuracies: 0.25 0.03125\n",
      "Epoch: 897 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 898 ;train and test accuracies: 0.34375 0.0625\n",
      "Epoch: 899 ;train and test accuracies: 0.0625 0.0625\n",
      "Epoch: 900 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 901 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 902 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 903 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 904 ;train and test accuracies: 0.1875 0.25\n",
      "Epoch: 905 ;train and test accuracies: 0.03125 0.15625\n",
      "Epoch: 906 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 907 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 908 ;train and test accuracies: 0.1875 0.09375\n",
      "Epoch: 909 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 910 ;train and test accuracies: 0.125 0.03125\n",
      "Epoch: 911 ;train and test accuracies: 0.34375 0.0625\n",
      "Epoch: 912 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 913 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 914 ;train and test accuracies: 0.3125 0.125\n",
      "Epoch: 915 ;train and test accuracies: 0.09375 0.15625\n",
      "Epoch: 916 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 917 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 918 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 919 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 920 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 921 ;train and test accuracies: 0.09375 0.125\n",
      "Epoch: 922 ;train and test accuracies: 0.25 0.0625\n",
      "Epoch: 923 ;train and test accuracies: 0.125 0.0\n",
      "Epoch: 924 ;train and test accuracies: 0.09375 0.0\n",
      "Epoch: 925 ;train and test accuracies: 0.125 0.21875\n",
      "Epoch: 926 ;train and test accuracies: 0.09375 0.09375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 927 ;train and test accuracies: 0.03125 0.03125\n",
      "Epoch: 928 ;train and test accuracies: 0.15625 0.15625\n",
      "Epoch: 929 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 930 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 931 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 932 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 933 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 934 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 935 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 936 ;train and test accuracies: 0.09375 0.0625\n",
      "Epoch: 937 ;train and test accuracies: 0.28125 0.03125\n",
      "Epoch: 938 ;train and test accuracies: 0.0625 0.125\n",
      "Epoch: 939 ;train and test accuracies: 0.15625 0.25\n",
      "Epoch: 940 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 941 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 942 ;train and test accuracies: 0.1875 0.0\n",
      "Epoch: 943 ;train and test accuracies: 0.15625 0.0\n",
      "Epoch: 944 ;train and test accuracies: 0.1875 0.21875\n",
      "Epoch: 945 ;train and test accuracies: 0.09375 0.0\n",
      "Epoch: 946 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 947 ;train and test accuracies: 0.09375 0.1875\n",
      "Epoch: 948 ;train and test accuracies: 0.03125 0.03125\n",
      "Epoch: 949 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 950 ;train and test accuracies: 0.125 0.125\n",
      "Epoch: 951 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 952 ;train and test accuracies: 0.0625 0.15625\n",
      "Epoch: 953 ;train and test accuracies: 0.03125 0.09375\n",
      "Epoch: 954 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 955 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 956 ;train and test accuracies: 0.21875 0.03125\n",
      "Epoch: 957 ;train and test accuracies: 0.125 0.15625\n",
      "Epoch: 958 ;train and test accuracies: 0.15625 0.03125\n",
      "Epoch: 959 ;train and test accuracies: 0.15625 0.09375\n",
      "Epoch: 960 ;train and test accuracies: 0.25 0.125\n",
      "Epoch: 961 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 962 ;train and test accuracies: 0.25 0.09375\n",
      "Epoch: 963 ;train and test accuracies: 0.1875 0.125\n",
      "Epoch: 964 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 965 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 966 ;train and test accuracies: 0.28125 0.0625\n",
      "Epoch: 967 ;train and test accuracies: 0.21875 0.09375\n",
      "Epoch: 968 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 969 ;train and test accuracies: 0.15625 0.125\n",
      "Epoch: 970 ;train and test accuracies: 0.1875 0.0625\n",
      "Epoch: 971 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 972 ;train and test accuracies: 0.03125 0.15625\n",
      "Epoch: 973 ;train and test accuracies: 0.125 0.1875\n",
      "Epoch: 974 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 975 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 976 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 977 ;train and test accuracies: 0.28125 0.125\n",
      "Epoch: 978 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 979 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 980 ;train and test accuracies: 0.21875 0.15625\n",
      "Epoch: 981 ;train and test accuracies: 0.125 0.21875\n",
      "Epoch: 982 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 983 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 984 ;train and test accuracies: 0.09375 0.09375\n",
      "Epoch: 985 ;train and test accuracies: 0.34375 0.125\n",
      "Epoch: 986 ;train and test accuracies: 0.1875 0.03125\n",
      "Epoch: 987 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 988 ;train and test accuracies: 0.0625 0.09375\n",
      "Epoch: 989 ;train and test accuracies: 0.0625 0.03125\n",
      "Epoch: 990 ;train and test accuracies: 0.21875 0.0\n",
      "Epoch: 991 ;train and test accuracies: 0.15625 0.0625\n",
      "Epoch: 992 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 993 ;train and test accuracies: 0.125 0.0625\n",
      "Epoch: 994 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 995 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 996 ;train and test accuracies: 0.03125 0.21875\n",
      "Epoch: 997 ;train and test accuracies: 0.125 0.09375\n",
      "Epoch: 998 ;train and test accuracies: 0.21875 0.125\n",
      "Epoch: 999 ;train and test accuracies: 0.1875 0.0625\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJztnXmYHFW1wH9nJpNMSEI2AgQCBEhkFUIISIJKhLDIQ1wIm4AQAnF7AgJPUVEE9AkPlSCgECFhkX3TiAoEBBWQhARCgAQkbCFAVrKSdWbO+6Orempqqruruqu6ejm/75tvqqtu3Tq3lnvuOffec0VVMQzDMAyAhrQFMAzDMCoHUwqGYRhGFlMKhmEYRhZTCoZhGEYWUwqGYRhGFlMKhmEYRhZTCoaRAxFRERmSthyGUU5MKRhVgYi8IyLrRWSt5++6tOWKExEZ7CiiLmnLYtQv9vIZ1cQXVPXxtIUwjFrGLAWj6hGRM0TkGRG5VkRWichrInKY5/h2IjJVRD4SkfkicrbnWKOI/FBE3hSRNSIyS0R28GQ/RkTeEJEVInK9iEjA9bdzrJh+nn37icgyEWkSkSEi8g9HtmUick8RZewmIhNF5APnb6KIdHOObSUiD4vISqeM/xKRBufY90Xkfadsr3vvi2EEYUrBqBU+BbwFbAVcAjzoqaTvAhYC2wFjgf/1VI7nAycDRwNbAmcC6zz5HgMcAOwLnAAc6b+wqn4A/Bs4zrP7q8D9qroZuBx4DOgLDAKuLaJ8PwIOAoY5shwIXOwcu8Ap3wBgG+CHgIrIbsB/Aweoai9H9neKuLZRR5hSMKqJPzqtYffvbM+xJcBEVd2sqvcArwP/5bT6Pw18X1U3qOps4CbgNOe8s4CLVfV1zfCSqi735HuFqq5U1QXAk2Qq5SDuJKNccKyJk5x9AJuBnYDtHBmeLqLspwCXqeoSVV0KXOopw2ZgILCTU/5/aSaoWSvQDdhTRJpU9R1VfbOIaxt1hCkFo5r4kqr28fz93nPsfe0Y3fFdMpbBdsBHqrrGd2x7Z3sHIF9FucizvQ7omSPd/cBIEdkO+CygwL+cY98DBJghIq+KyJl5rpeL7Ry5XdzyAVwFzAceE5G3ROQiAFWdD5wH/BRYIiJ3O/IZRk5MKRi1wvY+f/+OwAfOXz8R6eU79r6z/R6wa6kXV9WVZFxEJ5BxHd3lKilVXaSqZ6vqdsDXgd8WMdT1AzLWhotbPlR1japeoKq7AF8AznfdY6p6p6p+2jlXgSuLLqRRF5hSMGqFrYFznI7d44E9gL+q6nvAs8AvRKRZRPYBxgN3OOfdBFwuIkMlwz4i0r9IGe4Evkamb8F1HSEix4vIIOfnCjKVc2uefLo5srp/DWT6RS4WkQEishXwE+APTv7HOJ3ZAqx28m4Vkd1E5FCnQ3oDsL7AdQ3DhqQaVcWfRcRbqU1T1S8729OBocAyYDEw1tM3cDJwA5mW9QrgElWd5hz7NRm/+2NkOqlfA9w8ozKVjJJZoKovefYfAEwUkd6ObOeq6tt58lnr+3048DMyHeFznH33OfsgU+7ryHQ0rwB+q6pPOQrwCjIKcjMZ5TihyLIZdYLYIjtGtSMiZwBnOW4SwzBKwNxHhmEYRhZTCoZhGEYWcx8ZhmEYWcxSMAzDMLJU3eijrbbaSgcPHpy2GIZhGFXFrFmzlqnqgELpqk4pDB48mJkzZ6YthmEYRlUhIu8WTmXuI8MwDMODKQXDMAwjiykFwzAMI0vV9SkYRiE2b97MwoUL2bBhQ9qilIXm5mYGDRpEU1NT2qIYNYApBaPmWLhwIb169WLw4MEELJRWU6gqy5cvZ+HChey8885pi2PUAOY+MmqODRs20L9//5pXCAAiQv/+/evGKjKSx5SCUZPUg0JwqaeyGslTN+4j73djkT0MwzCCSdxSEJFGEXlRRB4OONZNRO4RkfkiMl1EBictj2EkzfLlyxk2bBjDhg1j2223Zfvtt8/+3rRpU6g8xo0bx+uvv56wpIbRmXJYCucC88gsEOJnPLBCVYeIyElklgo8sQwyGUZi9O/fn9mzZwPw05/+lJ49e3LhhRd2SKOqqCoNDcHtsilTpiQup2EEkail4CxB+F9kVqMK4ovArc72/cBhYg5So0aZP38+e++9N9/4xjcYPnw4H374IRMmTGDEiBHstddeXHbZZdm0n/70p5k9ezYtLS306dOHiy66iH333ZeRI0eyZMmSFEth1DpJWwoTge8BvXIc357MwumoaouIrAL6k1lSMYuITMBZRnDHHXdMTFij9jjvPHAa7bExbBhMnFjcuXPnzmXKlCnccMMNAFxxxRX069ePlpYWPve5zzF27Fj23HPPDuesWrWKQw45hCuuuILzzz+fyZMnc9FFF5VaDMMIJDFLQUSOAZao6qx8yQL2deoGVtVJqjpCVUcMGFAwyJ9hVCy77rorBxxwQPb3XXfdxfDhwxk+fDjz5s1j7ty5nc7p3r07n//85wHYf//9eeedd8olrlGHJGkpHAwcKyJHA83AliLyB1U91ZNmIbADsFBEugC9gY8SlMmoM4pt0SdFjx49sttvvPEG11xzDTNmzKBPnz6ceuqpgfMNunbtmt1ubGykpaWlLLIa9UliloKq/kBVB6nqYOAk4O8+hQAwFTjd2R7rpLEBo0ZdsHr1anr16sWWW27Jhx9+yKOPPpq2SIZR/nkKInIZMFNVpwI3A7eLyHwyFsJJ5ZbHMNJi+PDh7Lnnnuy9997ssssuHHzwwWmLZBjVt0bziBEjtJhFdmzyWv0wb9489thjj7TFKCv1WGYjGiIyS1VHFEpnYS4MwzCMLHWpFERg3bq0pTAMw6g86lIpAHgGgRiGYRgOdasUDMMwjM6YUjAMwzCymFIwDMMwsphSMIyYiSN0NsDkyZNZtGhRgpIaRmfqZpEdwygXYUJnh2Hy5MkMHz6cbbfdNm4RjSpCFaZNg913h3LEAzWlYBhl5NZbb+X6669n06ZNjBo1iuuuu462tjbGjRvH7NmzUVUmTJjANttsw+zZsznxxBPp3r07M2bM6BADyagfNm6EI4+E5mZYvz7565lSMGqbCoqd/corr/DQQw/x7LPP0qVLFyZMmMDdd9/NrrvuyrJly3j55ZcBWLlyJX369OHaa6/luuuuY9iwYfHKb1QV7pyqgFiJiWBKwTDKxOOPP87zzz/PiBGZSAPr169nhx124Mgjj+T111/n3HPP5eijj+aII45IWVKjnjGlYNQ2FRQ7W1U588wzufzyyzsdmzNnDn/729/4zW9+wwMPPMCkSZNSkNCoRModq81GH9UBIu1/RnqMGTOGe++9l2XLMgsLLl++nAULFrB06VJUleOPP55LL72UF154AYBevXqxZs2aNEU2KoByKwWzFAyjTHzyk5/kkksuYcyYMbS1tdHU1MQNN9xAY2Mj48ePR1UREa688koAxo0bx1lnnWUdzXVOa2t5r1eXobNdqqzoRVNvYcPrMYx0PZa5Xli0CAYOzGyX8v1a6GzDMIwaoNyWgikFwzCMCqbcS3KbUjBqkmpzi5ZCzZZ106aM77NPn7QlSRUbfWQYJdLc3Mzy5ctrt7L0oKosX76c5ubmtEWJn27dMv9XrUpXjpQpt/vIRh8ZNcegQYNYuHAhS5cuTVuUstDc3MygQYPSFsNICBuSahgl0tTUxM4775y2GIZREj/9Kfzyl/Dcc+W9rimFuHHHf9aB68IwjOS49NLM/5//vLzXtT4Fo+JZuTKja+vctWzUKQsWlPd6iSkFEWkWkRki8pKIvCoilwak2VFEnhSRF0VkjogcnZQ8wTLC2rXlvKJRDH37Zv7X+SAUo04pd3iaJC2FjcChqrovMAw4SkQO8qW5GLhXVfcDTgJ+m6A8gfTq5dsRV5AgCzRkGEYMNJTZn5NYn4JmxgO67fAm58/vaFdgS2e7N/BBcvJYPW0YhlGIRHWQiDSKyGxgCTBNVaf7kvwUOFVEFgJ/Bb6TI58JIjJTRGaWbZihaRDDMCqAmpq8pqqtqjoMGAQcKCJ7+5KcDNyiqoOAo4HbRaSTTKo6SVVHqOqIAQMGJCmyYRhGXVMWb5WqrgSeAo7yHRoP3Ouk+TfQDGxVDpmO437GMK0clzIMwyiamuloFpEBItLH2e4OjAFe8yVbABzmpNmDjFIoi3/ofo5nGrbsoWEYlU25A+IlOXltIHCriDSSUT73qurDInIZMFNVpwIXAL8Xke+S6XQ+Q+shYI1hGEZIakYpqOocYL+A/T/xbM8FDk5KhrBMlHM5j9907tGx2cmGUXu43/Xuu8O8eenKEgILnV0GurIxuz2AJRmFkARr12ZewJUrk8m/HjEFbcTFa35vdmViSqEM9KG9kn6bBAOnuTPj3Cm5Ruk0NNhw4XIR10ROoyQ2by7v9epSKezKm9ntHqxrP2AfQFXi1l3Ll6ctSRVhFX7V0NZW3uvVnVI4ibt4Nv1ujMqkyiuKrcoymNkwykvNdDRXKofb3IRk8SoV8/+XRM3cShuwURJmKSTMeronl3kVt7JzUuXWg1FBxBVoslrfxyJlt47mBPn4YziWP2V/X8zlKUpTAtX8YRhGnFTYt9DaGr9I5bYU6sd9JMIWwBbOzymcwX/4ROhzgYzKbmxMQjrDSJcqcPGIdA6zXLYLQ8d74+5bvx6am7O7uyRQo5r7qAw8ySGcyRRWEHGoaJIKIWzzooJaRaFpack0oYzawf++ur8Tej87uVAq5Tvo7nFHH3EECxiE0Eac6qvcn05dKoU32RWAj+gX7cS4X8QKM30To6kp04Sq1rImXOFViQip0tSUbP6qMF+E78sFxWcybRo78D5tNLIL82OVrZzUpVJ4jMOBIpRCFVHzlUiFFSz0/c6TaMOGGn9mFcw/G4QhwG58FEt+I/EvHVM8ZimUgfs4HiC6+yhF2tqKbzHczQmcxm3xCpQ0kWpH5Uxu5lgezH9+3DVuzPl1jzowzrn+aXJLzSuSFxhWONHy5Zl7kmMhLvdxtdH5Zu1JJvrAkTxWkpwujfj8XYcc0jnR+vWh3iGzFJKiw53N9A2szq4EWvk0NkLPhrUdd4asCU7kPm7j9OCD5ag8w1Lkdc9gMjdzFnfwtXjlKNc9cK61JzOLOv1w/h6zQAHkux9RmrJF3tP9eKlwInf24tZb503W6nz/G2gvVlcyvbnvsUNR8vnp4lcK//xn50RbbNF5XwCmFJJEtcMdVho4jvtTFCgau/N67oOlVmRBb17EvERgeVTry5V51aqcSbqzhvO4mi4EB4GZwllOuvXRrp1LnhI4kTvb8yj0PNzxiw6P8MWirqn+lm++67a0BHcQl0LcQ24SVsju/fqz5343OB3Dq+jdMfHEiR3lyoVPMXahJbZy2OijMvMgx9FIC9vxbrgTPA/a3Vwfpi5yE2/cGHwsBJuJ3tt2CZeESxhT1K3Z/mjpYT+KPn1yHrqec7ia8/kWv82bRQNl/noCuJtTgg8EjdbxVabdCHg3QuTVFuUzTrrHNgptbaVVnAceWNLlD+DF7LZrPXTipps6/v75zzunCXiWnSyFEjClkAJtNLKcbYo+P6QVmMEzpjkqm+gauF8E/sPOgccu4bJwmXfrlv94yA+3KUdrvkM+ESuBLVnl/F+dV6bQuZZSESXaii0u3w6WQgKyJVbcUod4P/98SacPZkF221UKR/IYnHNOe6JXX+140sUXh8q7kYi9wxXUKWRKwaGlCubx5ZPxE7wduL/cr1pBpeASwTIRx7Tv5CaB0j6moNZ7EkTIdyuW8n1+ASJ8MowfnRz3pVgquCM+LoLul3qrwmuvLfkaXaIqBT9tbTSyGVCzFNKiLZf5mATu4jsRkXTmc3oEKNxvEVopRHBj5FUKoTMpwTIIuf9KvlfcNTzczUlcwQ8BOJ+rQ52T133kfWblrKA3bcp/vAKVRZx0cB/5yrp4cWeX0DL6IeL0kf/zn9DYSAtd+QmXWUdz1SBCX4oM4O8uvhORSvCZF6IrBSqDMHRyC8WgFMrA97iqpPMFGMiH2d+u26wQOe9LTBVvc9QOfJG87shyLxrjJ6hxFXe9m899dNq2j3Fa4x0d9r3kDLldupQOw1f/p8R3qhhMKZTA9/i/9h9lUOeBSmH1ahpKNVVjwK1/QlsKUfJ2/qetFFbTI9H8FVhJe4d7L9ayHe+jCJ/nLxzEvyHgWUfqaC6CH/CLWPPr2rW4hoNEaRS5ltFXvtJh93huomvAO6ol3kP/1z82z6jGxziSKZzRYd9itqE761jMgA77e/KxWQqVwKvsGSrdEN7kW1wPbMosExkHeVp3gUqhd2/25pVo+SfoSvAqBf8l1lEckSyFYsoW8pxFDIyWb0SEjkphWxbxPoMA+CvH8G9GBVojSSvL3l6LJYb3Zouwo6x8DCB4UlpeHnooK3N31nITZ3c4fDR/AbTke+gfGbg/L+RN39U3OqmVRkbxLFuzrFPauzZ+qSTZomJKIYBDQ04GGssDXM9/cyY3FU4cA7ncRy/5Z3um5K/9BRcxxLPUqZ9vMTlUPmP4a1wixconcsWziel+Kx2HRu4WMC/lbH4fcJ5kzk5rwmFEevBxUZdazLZFnedyExM67fsLx/BfPMw2xSgcD8UMF/fSQhe2YXHgsS/zJ37MZZ1nSSeEKQUPgiK0sSTi8NS+rImU/ik+HSm9S5Rhbhcm7IsMqgsu4soOv6/lWx1+r6G9L6W3rEIk+CV/gY7jz123Qeod7WXA+4yD3EJDeKvTvjYa+HGca4Pk6NPJdTwq3dlQ0vnFsh0fBO4/n19Hyyiw/KW9my10YWuW5Dx+GZdwAveWdI2wJKYURKRZRGaIyEsi8qqIXJoj3QkiMtdJc2dS8oQn88BP4q7QZ3yXayJd4cf8b2EpAjwaUTqarwocCZNcR/Xx3N5p33/zuw6/7+OE7PYq+nAUfwvMy6/83NtQyR3t54QcKVQIbxnD9hUowlkJWquRx9wXoGuR7qNSEMldjs1B838iuiEbSlQKZ3MTvQo0LmOZsR+CJAfnbwQOVdW1ItIEPC0if1PV59wEIjIU+AFwsKquEJH8QUvKyHMcFDrt9p4RI2EI2+LdlfkgQ51fWnKlGOcsy1E8A9Ju8fjbMGvoSS86xmryfzh3cWpg3rk6qytBKbQhgRXANZwfS/7eMoZ9T9poSPTexK0UusUxQs3PmsLW+nL6B+7fQIGJmyGIw/o5t0Dj8mbOgoe3gWOOKfla+UjMUtAMbq3Q5Pz53/KzgetVdYVzTm77qcyspScALTTyZW/0zRgoNEJHpJVP8Ryz2L/D/kpSCmcW6B9YwI4F8+jjn6HscAvjfHsyr00luI9Cj/Qp0sXirYDDPi9FYq+4vcStcBKxFLYsHNwy1/3sHXLob9L0ZUXhRIuD+x3iJNE+BRFpFJHZwBJgmqr6g4x/AviEiDwjIs+JyFE58pkgIjNFZObSHGFx4+ZjZ/hhF1r5I1+ONe9CSuEIHuc5RtLbU2kqwr4hZ7jmIk6lUKii6BSSIgJHMC3wWpVhKSTbDeet3JtCPq8TuYeBLIpXEI9Si1vh/CiE+zRuFOFzPBl4bDQBEUxTIGf8JS+RYuoUR6JvuKq2quowYBBwoIjs7UvSBRgKjAZOBm4SkU6R0VR1kqqOUNURAwYM8B9OhA0UH6OoEIWG1g3ljcD9p3BH4P5cbOtzax3DXyKdn49Cwdu2KHoAam6qylIokmIUX+wKwUfcSuE4Huq8swyzrnsk8E7GSahGQORFN6JTltFHqroSeArwWwILgT+p6mZVfRt4nYySqACEi/gFI8gE3foz8fnxbvfE/V8QEL/9+75RPC6j+Uek6zzLqA6/7+KrHRN8XNzQQICdCkSV7R/TClbQrgyKshRirmiSnBOgCJ/lX4nlXyxJuqaqlY9JvsUeSDVbCiIywG31i0h3YAzwmi/ZH4HPOWm2IuNO6jzmLiWu5CJmMQKAY5mayDWCOpd2YGEsee/MO/kT9OxZdN5lc+WIZDusK8FSSHI4ZRKzwePgNP6QtggVR2qrNlazUgAGAk+KyBzgeTJ9Cg+LyGUicqyT5lFguYjMBZ4E/kdViwwolDTJtBCXsVUi+SbNSJ4rnCgmPs0zQGX0KSRJrZev0llB7jU9/KRmPZVBKSQ2JFVV54B/xRVQ1Z94thU43/mrS3INk6sY1qwpOoBf3NS6GyPXaCyjPOzM27zAcHbJEYbeS5hBG3/ki3yJP8UhWju10qdg5CY1MzQsJbiY4qZS3StReYed0hahOihzJLhNdGUJ4aZKhVEKpYa+CGR18g0HUwoR+EeR4SnyEadSmOzvSK4xwq4vUOl8RL+0RTAC2ETX0MElw4SIT0Qp7Lpr/Hn6MKUQgcc4EoDnnc7nONhIMwvZPpa8xkccspoWd9S48ipE2iHAjWBaaaRnyGB9YYa3ricBV89WyfdBmlKIgNsRVagFENbz7c6UDjVppUy8xc6dQoe/V2J0Sj/VsPRpkmyMIaxCKdzNibHn2RZS0b3oj+hbURSnrGcxPHB/2s+5WEwpRMCtLGexP0N5jf2ZGZjuZfYomNc6umdnSsc507hUDuXv3MXJHfZdyMRQ5y4KGV02jFJ4gK8E7l9CeSYvugTNIwmy7B7l8Lz53MjZXMJPgfbZ8nGwrojWqP/6xeTh57d8I1S6SmoAxUUuyy/u/sKbOTPW/HJhSiEC/2Q0+/ASF/Ar5rMbL/hiE7m8xW4F8/JWjJU0qqaNBtb5Jub4O9/uY2yn837Fd0N30hVSCm0IqwmOZXNcnhWtkuCzASEQgp5XoYr+Gs5hkxON039/S6G1iE/YjeuV63cxfIfrQqWbFLCmQbnZQLei7lsuXKVwE+M77P8ZF8d2DYBv8dtY88uFKYVINPAy+wSH2vWwNkQHk7fFFLWS2FDg+qXQRkMnX6hfvuBKXUKPDiqkFDbTlLNFWe55HQudlc+8BCmFvC1gVeaxdzY0iHddiVJZUsT9mOezZONQCmGrkt8zgW/4QqqnQWOOOSHFKIt2pXBWh/0b6M4cPhlduByUy+1qSiEB1uZo5Xr5E1/Mbh8dMSbRjYxH0ExobR+9WV5SSI4gSyGcUtDQbjBvBXoV53f6EFtpzPkBxFOBhac1QI6gFbDCuApcpRDn3JR1RbiinmJ0h99+eT7Pw6WIREuBaqWSO9qL6QfIV56gWFlRFM+9HJ83ryQwpZAAYVryE5iU3X49RB9Ex/wzL27QDMzV9AusUL/Jb/lSUCAyH600FlQKQR3tUcI3e+X7Hr/s5HpppTFnSIuwSmGVRzGvjdGHD5nIuX7eDzGCzFUKYa2dG/h6wTSbi2g9rqd7hzkA/iGy75U4j+IfjtL5va/lHMTyChueW0yfh6sUgt5Zr8J4gyFA/oEq/+CzHX53nOVeHmVqSiEBVodwDxRyQeXDde9EHfK2zNcinE/nMc9e95H7ioexFDbSnHUfvc92eeV4jx1YQ0/eZyAgnT7EXC2iqzkvtFLwRpTdimWcFbC2cbEEKb9HOaLgec9zAABPh5jv8gyj+CY3FEzXQhMbc71LH3/M35xh1F78741bSc1lD47j/pJbpG7fyQr6Bn4LbkU5ibP5ZkRX0jq6I4XmCKxaBWM793udG2LARDHxtYKUgjsgwqsULufHQH6l4H82afQ31qVSUG3/S4JL+VkyGTtsdiyFKOG9FeFFX9SR5fTvdBPCuI+CXlTxuI8KybWJrgxgKXs560P4lUIrjZ1M8hkcwPlcTYuvApzCGYzkWZ7jU+07VTt8eBtp5lZO73C8FILKP52RBc+7m5PZiXd4KhMDMicH8zSfCRktdTNd2J73gw9usQVH89dOu/0Vz9vsDMBUjuVBjit5hJBr+W3BurytZ0FD+8nfcBowm7PrdeVhyy3hvvt85w/hXs9ysHESpBS2YXGHY+fxq6yyzVdm/71PIx5WXSqF5GliaxYzIURLrxg2ZT+K4MeX60NcF6KVHUYp5FpL1lUKhfyygrKRZlY5rSl//m00dCpDrlnACxnEc4zsFKDPba22OB9ZC00IiviWCPWPGAlDI60czZ99eyWUK2dBSNeMhvw0W2hieV53VAPf5dc8ySHZPV6lMIpnOI+JXMBVXMolQOnDRpc6z7UPKwOPeyvRnNfq6ih/p/Xmuj7DKJFc65uHsYAKWgoBDYpg91Fmn3vN5xgVSin4ZTSlUEMsZWt+H8In7CeX/7uPZ6m+dUUsABTUGRb0+rfSyGvs3mFfi69llmv5Qtd9VMhS8H947micc5ww4o90WnYDbvTcy+v4Ni/jX68JVnr6EVyl0NnX335/W2jk7CIWvO9CC4sCXGT+cm2iS86l2J/gUK7mvMBjUSoCt4IZnWNVMYCJfJdDeSr7u5UurFgBqPJvRtFGI7/mQjY4yqJU95HbZ5JreclQlsLG9kWcRGANvYH8rpc/cAoH83TgsQbasgoo7hDs/+ETAIHDqN2yKpK9r/nK0EojfVjB0xwMmPuo5gnzKu7Jq5wXEOPH+/FsLtCXUKjDy5vSTxsNrKIPx3E/i3OMklmcY5JaFEshSLY3GMpQ/sN4bu6Uxrsk6ne4jvucURnedH1Zka1M3A8v13wHWltDL3fppyFHZeaXeQDL2DLHUx/DEzljOUWptNxBDe45bzmuoEL0y9O/W6ql4M5X6cuKvGXJaynkIF+F+gHb8axTmfr5I1+KdK1cs5SD+DbX8wWm8jL7dDrmVYC5lEIDrVzAL4HMvV9Fn+wa55sSHH6eC1MKJTKNMfkTrFjBm47LIIzp+x47cU1AC9J7bjGTn9yXczizeMrjSvDjvrgPchwDWZbdP4Q36MFaTuAe/jvHRCXXUoiqFNzlSeczhPkMZVPR4QEasm4HN2BZ0JwAEaAh+qv/EF/KbvutKehcLvfjj7rwW5Cl0CtHWG3XinOvHceM4VLzeJZRvMOOnMVNOUequYTtU3AbHP70u/Bm1kWYy8IZyn+4kF92OP44h+W9Xod7kKcPagE7sJ4teJgvBB4PcpX576/SkN3nyvhNfsd3+A3/4jN55UwCUwolcgTT8g69k759mM5BQPsLvQtvRr6Ot8XQxTP6oqBSAh7j8GzoihcZnvUdB1kPuT6sNxnCOnpwHyewJkfr23X7+Fs3P+fKJ/KUAAAbSklEQVSHHX77K8+fcBkA7zC4QEnaKTTWvYcT2CzMRLF9eInPhljq9AxuAeBsJrGZrpzAPR2ON+RQCvm4MWCGb1DrOldF7SpQV5Hkq9Bv4gyO596CMoV1H+WqKtfTnZ15l3nsGXj/w/QptPq8Jm4/yAwO7LD/bXbJThrLldcitqWNxg7Hj+QR+rKEvjmWjc2Vl1fBb6Abn+A/HY5P98nnLatbhiCl71cYq+nNdXwnUIakMaUQA/cUCDDmtqDdDtS32aVzojzDoR7nMJSGbDygNk9r6QimFZTvWKaGnuRUSivxJO5mV+YXHEHhr/Qm8XXHv9yUM01UnmI0t3A6Z+cYiur9uF9mH15lr5x5PemMu19Nb4Q2buLsDsfX57BswrSCv8GNnfa9FxBvyVtRC23McIa3bo5gKZzNFO73TIbKRamWgrfcxSqFLr5bt4iBjORZxjGlU1p/K9uPu997vI0urGQAK3NMOgxzDz6mBxt9/WcH8wxdae8PccvaQFvWws83I95/3TSWoK3vcJUx8QRjaKWBRtqyvkEv7ktSzExOoQ3X9/81bmM1vbidMwqc0/FFyuXOCXrdSulk3EB33gqY+9DN85EEyVeIsdyd81iue7qJboxzWvZhyOe7PYpH2CIbKrnz9Z73tQ7bif68t2chHwRMhGul0dOZ3J7vRkcpvMFQAO5nLHs5llexlNrR7LWQ8llq/o7mO/gqp3Bn+3Hf7Xsux7DfXBWqS5BS8HIat/EhAwPzdOUI+8a2+qY2et/PfJaCK1slKIVQT19EdhWRbs72aBE5R0TCL2haB7itgEcDJgup86ALKYU2z7tyCE85YSzaz1lHD87kFsJWNn/haC7m8k7p21+08O4jP2FmCb/rdJb18MWoj/qiP5DHEvPnFdV/75LP1bOJboEtSvfam0K4icLiVwjuRMA2GvgHo7OzhV1chf8ug9mWhVzPt0uWIVfl+ivO5you7LTfPyvZW9G/GzAEN5elcGqR64G4+RWyFNxr+V1Qf+A0nnDcsO4zjSukhLesYSwF/3XTCL8d1lJ4ABghIkOAm4GpwJ3A0UkJVm0sYWt6sTbwZdpYwLx1afR8i//M0xlcCPfFvpGv82eOLXzC5s3Q5FZs4WrVj+mRc0ES9/ruR1DKSmO3cVrgfrfjMa5QzJt9rqsoVl3YOQXFcDDPMJqnaMvRgvQO/13M9vRjecnXzHVPL+RXAPyPxxoewhud4j55lcIEJvFvRnIgM7JrLhQzea0UudvnBzRxINN5PUQU43bffmlhxcMqBTedvww38nWGMTsWZR+WsG9zm6q2AF8GJqrqd8Fnb9U5rXmsgdVOjKJyBwLLdT31fZydHLghCDMCyr0nH9GPnqzhV5wPhLMU3E7riTnG8m/NEqB9opSXYqwFf6Ubhmec4Y83FjEfJSzvMphb87gL/XNC4mjhRsnjTYbwkW/osreiX01vruE8TuFOTnMsAe97Gef6CoUsBci4+lY7cx6C8FsKf+S4kmRyO8HfYGjWfRSkFFwXq9+NuYlujGdyzjD9SRD26W8WkZOB0yEbQjGBBUirl3wTYyZyAVC+KIeF+BefYRJnc3oEn7ufKEqhkVY+pidTHavFH6UziAc5jt6s4MUc48W3ZRGQGVkSJ3MjBCd8n0EIygMB60sUwyMBrsdC+CcWxtHwKFRRH85jBWQK18got6VQTF6levRv43QEZRHb5lUKPZ2Z9uWOAhxE2Ls1DhgJ/FxV3xaRnYE/JCdW9eG+3EEP3H0pk7IU7uEEvsatodO30oWvM4k3GcrmcEsgdCLM6mFepQAZl5igzAq5xvXqgCiwLtOclc5mxdiCGsHzoWMOJcHneSTyOf7+jDgaHoWUwrOMynu8UEW/0RO7Kw5LoVCfQjEd/u3fbOc8d2Ne5PxAsg2pv/BfnY5WnVJQ1bmqeo6q3iUifYFeqnpFvnNEpFlEZojISyLyqohcmiftWBFREQlXWyRIsbHS3A8haE2Bwi9taZzEPdzO17K/o3Tkdu1anLslTGXsVwpx8ju+yZas4p2QM3jDMIsRnVwhlYr7jP2WQntlVjxB7+mevJrdXscW3MdY3gwYOpuRKb9SeJCv8DN+xIX8siyWQjHkC4e9vsiV8zbRjZ14h3FMyUYofs3p33AHY1SNUhCRp0RkSxHpB7wETBGRXxc4bSNwqKruCwwDjhKRgwLy7gWcA0yPJnpl4b6QQUohjKVQ7KiZfCTZh3FenjDEfiWYTPwWyTmJrp7wh2CPYpXmeuf8letL7MM8Z31y50xO4D6GsiDw/EIVfStd+DE/YxV9spVgKesPuxV3HO/7ydzJXPbIWjNtAXmWonwWsBOb6MZQ5iMoe/AaUIWWAtBbVVcDXwGmqOr+kH8qrWZwQ1K68W6DGjCXA/8HbAgpS0XyljMhLSgYXNLuIz/FjG1+pcNH78krh8j5QlG0t2Jzu9SMePBXwO675p9dHQW/yyRq/J0oleYiBrIHc3NOMgyD2xALM4O8EH/iy+zF3M6DMTzEaZG4/MMZbegfLpsGYZVCFxEZCJwA4dfqE5FGEZkNLAGmqep03/H9gB1UNW+eIjJBRGaKyMylS5eGvXxZGc/NfI1beCVgTdak3Ue5iKKEPsnswGUm87EXr/AHTgHyh2ZII/xvGtzphBIBODCC4fsVHuAwHo90rVwzmDvMfI6hDfI0B0deMD7qEN3X2KOkYb254iKVgnt/g6RKQincySn0YzmzfWuepEHYu3gZ8CjwjKo+LyK7AG8UOklVW4FhzkS3h0Rkb1V9BUBEGoCrocD03Ew+kyCzfuWIESMSm+JXytora+nF7d6FXDyU21L4Fr/l5/yIx0PERWqnKXLVPZe9mJvDwoBk+xQqka9xG9/lVyzWgTwf4VE/5IQvicI89mB/XuADXwjvuN+xz+QIRR3EewxiBxaWdL3JjAsVr8pLkkrB/SaO4c/ZUOBJNe5WVMjSpKHuoqreB9zn+f0WhB/Aq6orReQp4CjgFWd3L2Bv4CnJNGm2BaaKyLGqOjNs3tVAuS2FBezEaRUwOGwK4+jOeq5NKbBXKdzGaTwWYolNL610YUmZpu98nRu5ndN4zBmF5ZLmsOcDmcEeRY3MaWc8k0OlG8p/sjHF3P9JKAXXgvkLx8SWd6UT6i6KyCDgWuBgMv0CTwPnqmrOZoGIDAA2OwqhO5k+iCvd46q6CtqXjHKUxoW1phAgYLJYnbCErTutiFYtnM5taYuQl3X04LGAeQ2uUng+5LDfOFnEQBaVSSnOd2I9QbKWQjHDWaudsM2KKWRCW2wHbA/82dmXj4HAkyIyB3ieTJ/CwyJymYiEiL1Qe9SyUvCWzf2gulX32IEqRRjJsxxRYIJZLZGEUnAJcqm67q0r+X7s16sEwt7FAarqVQK3iEhw/AEHVZ0DnXtNVPUnOdKPDilLrKxfD91LC29SkDiHzFUqQR3N/uioRnnIFU00ChdyVTaMR6WTpKUQ9MVupmsq0UvLRVhLYZmInOqMJmoUkVMhhshbFUBzc96lDGIh7siL1ULtqsDa51dcGItyKQe5+hTuKyH8SKU25Mox+DJsLXUmmeGoi4APgbFkQl8YIXCHZFbaC5Y8tduaSpMkGzDVSK55Cidwb9Et+vaGXGV9s7NmJX+NsGEuFqjqsao6QFW3VtUvQRHj6OqUerMU5jgLmPsXLqkXkpidbuQmt/uo+Afxv/yQlfRmSgkzrZNg06bCaUqllFrq/NikqDDibonVm6XwQ/6XUTzDv/hs2qIYdcB0PgXAQgbFludzjKQvK5leYS60lmjzS4uiFKVQHzVcDLiLzARFR6xFWmji34zCXpFomFuoOC7hUvbiFV98ptqk2KjGUSilu95e4ZAsZyu2ZyGL2SZtUQyj5mijkbnslbYYZSF1pSAiawiu/AVKXKeuzghajN0wDCMK5ehTyKsUVDVaEBKj7qiXfhLDqASaOwdhjp36GA5jGIZRA3z1q8lfw5SCYRhGmejRAxrjj7wdK6YUjJKo5en+9YKNeiofa9fC/vEtK54IphSMknjbWSPZXXnOMIz8TA4XHTw14g8raNQVd3MShzKNmzgrbVEMo6JxLbK9Knz0rCkFo0SECSEXRjEMo/Ix91EOzM9qGEY9YkrBqBpMURtG8phSMBLFX5FbxV48ixfDxx+nLUXppPEOuGumVMr7ly+S7urV5ZMjCOtTMIwqYeut05bAiIvGxs4RTytFYZmlkIe1a2FjHa4oWSkvp2HUKl2KaI4fdFD8cgRhlkIeevRIWwLDMGqRYpRCW1v8cgRhloJhGEaZ6do1+jnlsuBNKRiGUVdUwuSxLbaIfk7VKwURaRaRGSLykoi8KiKXBqQ5X0TmisgcEXlCRHZKSp56oJJGV1Qyhe6R3cfaZvTotCWALbeMfk4tuI82Aoeq6r7AMOAoEfF3lbwIjFDVfYD7gf9LUB4jAvXYwV7NtLTAsmVpS1EdXHdd2hJAv37Rz6l6S0EzrHV+Njl/6kvzpKquc34+BzGuvJ0A9dR6jOrzTLp1XWreuc5PUvkleT/8yzI2NkL//sldz4iXgQOjn1P1SgFARBpFZDawBJimqtPzJB8P/C1JeYrF3Am1S9euuZ9tJT/3YkavGJXDkCHRz6kJpaCqrao6jIwFcKCI7B2UTkROBUYAV+U4PkFEZorIzKVLlyYnsGGUiUpVNn6qRc6k+cIX4s3vwAOjn1MTSsFFVVcCTwFH+Y+JyBjgR8CxqhpozKvqJFUdoaojBgwYkKishlELWGUeL1Onxpvf7rtHP6fqO5pFZICI9HG2uwNjgNd8afYDbiSjEJYkJYuRbiWxcWMmnktrazrXtwrSKJW436FilEK5SNJSGAg8KSJzgOfJ9Ck8LCKXicixTpqrgJ7AfSIyW0Ri1sflYZtt0pagsunaFXr1ggabFWNUIar5A9iVi3JZCol1V6nqHGC/gP0/8WyPSer65WTPPTMRLI3qpVI+fMPIRU31KdQ6n/lMutdPapRMrbld0h5NVI7wzd78y1XWXOWqtfcnbqLeH1MKVcQXv5i2BMljH3h+ct2f9eszk8r88wqisnx5aecb1U+5vkEb7RwDw4dHP8d9wOVyWVilnjxBLqjm5sxfqfkaxbNuXeE01YApBSNW6slfXqzCtcq39ojyTJPsV4rj3TL3kVGVrF6dcZmk7b+HdGVYtSqd6/pJ+xnUEmnfS1MKNUjaL1U56NWrOHdJJSiROCkmCma5qKX7XKlEDY2d75mUeyi3KYUiSWsiVlRqrbKtVewZxU8p97SUkWJ9+sDHHxd/7XwylQPrU4hIJQ0js4rEMDqT9nex227J5Gvuozqh2Aed1AuS9gdlpE855lPkGxFU7e/gj36UTL5VP6PZCKaYF77cw1eDrl0NVJOsYanFMgF07562BMkRd0TVcmOWglETbNiQtgSVS60qlo8+SluC5BGBpqbMdrkGL5hSMGqCbt3SliAekqrA3Y7PShkqGwd9+6YtQXl45JHMqnoPP1ye65n7KEFq6QOsZ7wVdSEXXpyVepx5bbFF7VgM+VbKqzbCyDx6dHnX3zZLIUEqbax6NX401UC5OgCrgU2bMhMYW1rSliQ/9i3kxiyFKqLSXuS45Km0ckWhmmX3EleIh6amdh94ua8dlVKvG3T+4YeXJlMlYJZChVLplU2pE4OSyNcw0uaxx9KWoHRMKdQZVukaRjLUyrdlSsEwjIpj06byXs9d7yLqpL0wo96qTVmYUogJ/8uU5otgY/YLU8kxodKSbcWKTITbSqCpqTz3wb1GlyJ7V6MGvqsGTCnUIN26RfugyhHWwKh8+vQpfUGgcnPIIelev1ev3Meq9ZsypWBUNNX6YRnJsHJlx99PPpmOHC59+qR7/SQwpWAYRl7iHHpcal69e3f8Xe6hrH6retSo8l6/HJhSMIwIVJLV4kYa9beekyYu660WrMDRo9OWIH4SUwoi0iwiM0TkJRF5VUQuDUjTTUTuEZH5IjJdRAYnJU8S1MJLbVQv3btn3j9/69koHyeckLYE8ZOkpbAROFRV9wWGAUeJyEG+NOOBFao6BLgauDJBeQzDqEHSbJylMRM7aRJTCpphrfOzyfnzP7ovArc62/cDh4nU4m02aol6tA5thFr9kGifgog0ishsYAkwTVWn+5JsD7wHoKotwCqgf0A+E0RkpojMXLp0aZIiGxVOvhW7yolVkOHugSmT6iNRpaCqrao6DBgEHCgie/uSBFkFnV4fVZ2kqiNUdcSAAQOSEDU27ANIllpescuoTmrtmy/L6CNVXQk8BRzlO7QQ2AFARLoAvYE6WE8pHLX2shlGLvr1S1sCwyXJ0UcDRKSPs90dGAO85ks2FTjd2R4L/F3VqkHDSJpKc+ssX562BIZLkuspDARuFZFGMsrnXlV9WEQuA2aq6lTgZuB2EZlPxkI4KUF5DMMwjAIkphRUdQ6wX8D+n3i2NwDHJyWDEUxai5oYRj4qxWqpd2xGs2EYhpHFlEIFUEm+XcMw6htTCkbFElZR2voRhhEfSXY0GxExayE6ds8MI15MKdQpVpkahhGEuY+MqsUUm2HEj1kKRmisEjaM2scsBcMwDCOLKQXDMCoas1DLiykFwzAqnnqby9PYmPl/8snlv7b1KRgVx9q1sH592lIYRnq0tKR3bVMKRsXRo0fmzzCM8mPuI8MwDCOLKQUjFerJP2wY1YQpBcNIibVrM/83bkxXDsPwYn0KhpESPXqYxWRUHmYpGIZhGFlMKRiGYRhZTCkYhmEYWUwpGIZhGFlMKRiGYRhZbPSRUXXYiB3DSA6zFAzDMIwsiSkFEdlBRJ4UkXki8qqInBuQpreI/FlEXnLSjEtKHsMwDKMwSbqPWoALVPUFEekFzBKRaao615Pm28BcVf2CiAwAXheRO1R1U4JyGYZhGDlIzFJQ1Q9V9QVnew0wD9jenwzoJSIC9AQ+IqNMDMMwjBQoS5+CiAwG9gOm+w5dB+wBfAC8DJyrqm0B508QkZkiMnPp0qUJS2sYhlG/JK4URKQn8ABwnqqu9h0+EpgNbAcMA64TkS39eajqJFUdoaojBgwYkLTIhmEYdUuiSkFEmsgohDtU9cGAJOOABzXDfOBtYPckZTIMwzByk+ToIwFuBuap6q9zJFsAHOak3wbYDXgrKZkMwzCM/CQ5+uhg4DTgZRGZ7ez7IbAjgKreAFwO3CIiLwMCfF9VlyUok2EYhpGHxJSCqj5NpqLPl+YD4IikZDAqG5uZbBiVh81oNgzDMLKYUjAMwzCymFIwDMMwsphSMAzDMLKYUjAMwzCymFIwDMMwsphSMAzDMLKYUjAMwzCyiFbZDCIRWQq8W+TpWwH1NmPaylwfWJnrg1LKvJOqFowoWnVKoRREZKaqjkhbjnJiZa4PrMz1QTnKbO4jwzAMI4spBcMwDCNLvSmFSWkLkAJW5vrAylwfJF7muupTMAzDMPJTb5aCYRiGkQdTCoZhGEaWulEKInKUiLwuIvNF5KK05YkLEdlBRJ4UkXki8qqInOvs7yci00TkDed/X2e/iMhvnPswR0SGp1uC4hCRRhF5UUQedn7vLCLTnfLeIyJdnf3dnN/zneOD05S7WESkj4jcLyKvOc96ZB084+867/QrInKXiDTX4nMWkckiskREXvHsi/xsReR0J/0bInJ6sfLUhVIQkUbgeuDzwJ7AySKyZ7pSxUYLcIGq7gEcBHzbKdtFwBOqOhR4wvkNmXsw1PmbAPyu/CLHwrnAPM/vK4GrnfKuAMY7+8cDK1R1CHC1k64auQZ4RFV3B/YlU/aafcYisj1wDjBCVfcGGoGTqM3nfAtwlG9fpGcrIv2AS4BPAQcCl7iKJDKqWvN/wEjgUc/vHwA/SFuuhMr6J+Bw4HVgoLNvIPC6s30jcLInfTZdtfwBg5wP5VDgYTLLvi4DuvifN/AoMNLZ7uKkk7TLELG8WwJv++Wu8We8PfAe0M95bg8DR9bqcwYGA68U+2yBk4EbPfs7pIvyVxeWAu0vmMtCZ19N4ZjM+wHTgW1U9UMA5//WTrJauBcTge8Bbc7v/sBKVW1xfnvLlC2vc3yVk76a2AVYCkxxXGY3iUgPavgZq+r7wC+BBcCHZJ7bLGr7OXuJ+mxje+b1ohQkYF9NjcUVkZ7AA8B5qro6X9KAfVVzL0TkGGCJqs7y7g5IqiGOVQtdgOHA71R1P+Bj2t0JQVR9mR3XxxeBnYHtgB5kXCd+auk5hyFXOWMrf70ohYXADp7fg4APUpIldkSkiYxCuENVH3R2LxaRgc7xgcASZ3+134uDgWNF5B3gbjIupIlAHxHp4qTxlilbXud4b+CjcgocAwuBhao63fl9PxklUavPGGAM8LaqLlXVzcCDwChq+zl7ifpsY3vm9aIUngeGOiMXupLpsJqaskyxICIC3AzMU9Vfew5NBdwRCKeT6Wtw93/NGcVwELDKNVOrAVX9gaoOUtXBZJ7j31X1FOBJYKyTzF9e9z6MddJXVQtSVRcB74nIbs6uw4C51OgzdlgAHCQiWzjvuFvmmn3OPqI+20eBI0Skr2NlHeHsi07aHSxl7Mg5GvgP8Cbwo7TlibFcnyZjJs4BZjt/R5Pxpz4BvOH87+ekFzIjsd4EXiYzuiP1chRZ9tHAw872LsAMYD5wH9DN2d/s/J7vHN8lbbmLLOswYKbznP8I9K31ZwxcCrwGvALcDnSrxecM3EWm32QzmRb/+GKeLXCmU/75wLhi5bEwF4ZhGEaWenEfGYZhGCEwpWAYhmFkMaVgGIZhZDGlYBiGYWQxpWAYhmFkMaVgGD5EpFVEZnv+YouqKyKDvdEwDaPS6FI4iWHUHetVdVjaQhhGGpilYBghEZF3RORKEZnh/A1x9u8kIk848e2fEJEdnf3biMhDIvKS8zfKyapRRH7vrBXwmIh0T61QhuHDlIJhdKa7z310oufYalU9ELiOTMwlnO3bVHUf4A7gN87+3wD/UNV9ycQqetXZPxS4XlX3AlYCxyVcHsMIjc1oNgwfIrJWVXsG7H8HOFRV33KCEC5S1f4isoxM7PvNzv4PVXUrEVkKDFLVjZ48BgPTNLN4CiLyfaBJVX+WfMkMozBmKRhGNDTHdq40QWz0bLdifXtGBWFKwTCicaLn/7+d7WfJRGwFOAV42tl+AvgmZNeU3rJcQhpGsVgLxTA6011EZnt+P6Kq7rDUbiIynUyD6mRn3znAZBH5HzIrpI1z9p8LTBKR8WQsgm+SiYZpGBWL9SkYRkicPoURqrosbVkMIynMfWQYhmFkMUvBMAzDyGKWgmEYhpHFlIJhGIaRxZSCYRiGkcWUgmEYhpHFlIJhGIaR5f8BT0LuqvagGiYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d5ef7dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##training loop\n",
    "train_losses = []\n",
    "train_iterations = []\n",
    "test_losses = []\n",
    "test_iterations = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    net.train()\n",
    "    #load the batch of data\n",
    "    data,labels = sample_data(ModelNet40Data.train,BATCH_SIZE)\n",
    "    data = torch.from_numpy(data).float().to(device)\n",
    "    labels = torch.from_numpy(labels).to(device)\n",
    "    \n",
    "    #compute the loss\n",
    "    preds,M2 = net(data)\n",
    "    loss = criterion(preds,labels)\n",
    "    \n",
    "    #add transformation matrix regularization loss\n",
    "    I = torch.eye(64).unsqueeze(0).to(device)\n",
    "    loss2 = torch.mean(torch.norm(torch.bmm(M2,M2.transpose(2,1)) - I, dim=(1,2)))    \n",
    "    loss += REG_WEIGHT*loss2\n",
    "    \n",
    "    train_losses.append(loss.detach().cpu())\n",
    "    train_iterations.append(epoch)\n",
    "    train_accuracy = compute_accuracy(preds,labels)\n",
    "    #step the optimizer\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch%TEST_EVERY == 0:\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            #load the batch of test data (batch size couldn't be too big)\n",
    "            data,labels = sample_data(ModelNet40Data.test,32)\n",
    "            data = torch.from_numpy(data).float().to(device)\n",
    "            labels = torch.from_numpy(labels).to(device)\n",
    "            \n",
    "            preds,M2 = net(data)\n",
    "            test_loss = criterion(preds,labels)\n",
    "            #add transformation matrix regularization loss\n",
    "            I = torch.eye(64).unsqueeze(0).to(device)\n",
    "            test_loss2 = torch.mean(torch.norm(torch.bmm(M2,M2.transpose(2,1)) - I, dim=(1,2)))    \n",
    "            test_loss += REG_WEIGHT*test_loss2\n",
    "\n",
    "            test_losses.append(test_loss.detach().cpu())\n",
    "            test_iterations.append(epoch)\n",
    "            test_accuracy = compute_accuracy(preds,labels)\n",
    "            print('Epoch:',epoch, ';train and test accuracies:',train_accuracy,test_accuracy)\n",
    "\n",
    "#     clear_output()\n",
    "    plt.plot(train_iterations, train_losses, 'b',test_iterations, test_losses, 'r')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss') \n",
    "    plt.legend(['Train','Test'])\n",
    "    plt.title('Epoch vs Loss')\n",
    "#     plt.show()\n",
    "    plt.savefig(\"./cls_losses.png\") # save graph for training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
