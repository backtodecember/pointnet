{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from dataset import ShapeNetDataset\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_data(dataset,data_type,batch_size):\n",
    "    pcds,labels,fns = dataset.get_data(data_type,batch_size)\n",
    "    return pcds,labels\n",
    "    \n",
    "def get_all_data(dataset,data_type):\n",
    "    pcds,labels,fns = dataset.get_data(data_type,batch_size)\n",
    "    return pcds,labels\n",
    "\n",
    "def compute_mIoU(preds,target):\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    target = target.cpu().detach().numpy()\n",
    "    N_of_parts = np.max(target)\n",
    "    N_of_pts = np.shape(target)[0]\n",
    "    total_IoU = 0.\n",
    "    for i in range(N_of_parts):\n",
    "        U = [False]*N_of_pts\n",
    "        I = [False]*N_of_pts\n",
    "        for j in range(N_of_pts):\n",
    "            if target[j] == i and preds[j] == i:\n",
    "                I[j] = True\n",
    "            if target[j] == i or preds[j] == i:\n",
    "                U[j] = True\n",
    "        if sum(U) == 0: \n",
    "            total_IoU += 1\n",
    "        else:\n",
    "            total_IoU += sum(I)/sum(U)\n",
    "    return total_IoU/N_of_parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters\n",
    "N_CLASSES = 16\n",
    "EPOCHS = 1000#2000\n",
    "BATCH_SIZE = 32\n",
    "INIT_LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "LR_STEP = 20\n",
    "SCHEDULER_GAMMA = 0.5\n",
    "EVAL_EVERY = 1\n",
    "REG_WEIGHT = 0.001\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_ID = 0\n",
    "ShapeNetData = ShapeNetDataset('datasets/ShapeNet/',class_ID)\n",
    "N_of_parts = ShapeNetData.get_N_parts(class_ID)\n",
    "net = PointNetDenseClassification(N_of_parts).to(device)\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=INIT_LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP, gamma=SCHEDULER_GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mIoU: 0.0\n",
      "tensor(1.4026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mIoU: 0.0\n",
      "tensor(1.3937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mIoU: 0.0\n",
      "tensor(1.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mIoU: 0.15533037180059814\n",
      "tensor(1.3886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mIoU: 0.1711923886380641\n",
      "tensor(1.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "mIoU: 0.15424808922468053\n",
      "tensor(1.3879, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5afe8ef2f91a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mREG_WEIGHT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmIoU_one_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mmIoU_batch\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mmIoU_one_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-048f3145e249>\u001b[0m in \u001b[0;36mcompute_mIoU\u001b[0;34m(preds, target)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtotal_IoU\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_IoU\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_of_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "##training loop\n",
    "train_losses = []\n",
    "train_iterations = []\n",
    "eval_losses = []\n",
    "eval_iterations = []\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    net.eval()#to allow for batch of 1\n",
    "    #load the batch of data\n",
    "    all_data,all_labels = sample_data(ShapeNetData,'train',BATCH_SIZE)\n",
    "    mIoU_batch = 0.\n",
    "    for data,labels in zip(all_data,all_labels):\n",
    "        data = torch.from_numpy(np.expand_dims(np.array(data),0)).float().to(device)\n",
    "        labels = torch.from_numpy(np.expand_dims(np.array(labels),0)).to(device)\n",
    "        \n",
    "        #compute the loss\n",
    "        preds,M2 = net(data)\n",
    "        loss = criterion(preds[0,:,:],labels[0,:])\n",
    "    \n",
    "        #add transformation matrix regularization loss\n",
    "        I = torch.eye(64).unsqueeze(0).to(device)\n",
    "        loss2 = torch.mean(torch.norm(torch.bmm(M2,M2.transpose(2,1)) - I, dim=(1,2)))    \n",
    "        loss += REG_WEIGHT*loss2\n",
    "        \n",
    "        mIoU_one_part = compute_mIoU(torch.max(preds[0,:,:],dim = 1).values,labels[0,:])\n",
    "        mIoU_batch +=mIoU_one_part \n",
    "        \n",
    "    train_losses.append(loss.detach().cpu())\n",
    "    train_iterations.append(epoch)\n",
    "    print(\"mIoU:\",mIoU_batch/BATCH_SIZE)\n",
    "    #step the optimizer\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(loss)\n",
    "#     if epoch%EVAL_EVERY == 0:\n",
    "#         with torch.no_grad():\n",
    "#             net.eval()\n",
    "#             #load the batch of eval data (batch size couldn't be too big)\n",
    "#             data,labels = sample_data(data,'eval',32)\n",
    "#             data = torch.from_numpy(data).float().to(device)\n",
    "#             labels = torch.from_numpy(labels).to(device)\n",
    "            \n",
    "#             preds,M2 = net(data)\n",
    "#             test_loss = criterion(preds,labels)\n",
    "#             #add transformation matrix regularization loss\n",
    "#             I = torch.eye(64).unsqueeze(0).to(device)\n",
    "#             test_loss2 = torch.mean(torch.norm(torch.bmm(M2,M2.transpose(2,1)) - I, dim=(1,2)))    \n",
    "#             test_loss += REG_WEIGHT*test_loss2\n",
    "\n",
    "#             test_losses.append(test_loss.detach().cpu())\n",
    "#             test_iterations.append(epoch)\n",
    "# #             test_accuracy = compute_mIoU(preds,labels)\n",
    "# #             print('Epoch:',epoch, ';train and test accuracies:',train_accuracy,test_accuracy)\n",
    "\n",
    "# #     clear_output()\n",
    "#     plt.plot(train_iterations, train_losses, 'b',test_iterations, test_losses, 'r')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss') \n",
    "#     plt.legend(['Train','Test'])\n",
    "#     plt.title('Epoch vs Loss')\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"./cls_losses.png\") # save graph for training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
